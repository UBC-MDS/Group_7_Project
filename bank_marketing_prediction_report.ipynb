{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6d6f62-2ef0-4b37-afaf-fc6d8fb28c7f",
   "metadata": {},
   "source": [
    "# Predictive Analytics for Direct Marketing Campaign: A Banking Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e0892-6c68-47d7-a964-352d0fe2bae7",
   "metadata": {},
   "source": [
    "by Gretel Tan, Yan Zeng, Charles Xu & Riya E. Shaju 2023/11/19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e64285-6422-4821-b736-2b7820795836",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793acfc-0a80-4665-854f-1897035910a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631cbaa-8d2f-4463-be32-697987c32932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.knn_model import KNNModel\n",
    "from src.models.lr_model import LRModel\n",
    "from src.models.svc_model import SVCModel\n",
    "from src.models.rf_model import RFModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24778c0d",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this project, we aimed to use customer information from a phone-call based direct marketing campaign of a Portugese banking institution to predict whether customers would subscribe to the product offered, a term deposit. We applied several classification based models (k-NN, SVM, logistic regression and random forest) to our dataset to find the model which best fit our data, eventually settling on the random forest model, which performed the best among all the models tested, with an F-beta score with beta = 5 of 0.817, and an accuracy of 0.671 on the test data.\n",
    "\n",
    "While this was the best performing model out of the models tested, its accuracy still left much to be desired. This indicates that perhaps more data is needed to accurately predict whether customers would subscribe to the term deposit. Future studies may also consider using more features, a different set of features which might be more relevant to whether customers will subscribe, or utilising feature engineering to obtain features which might be more useful in helping to predict whether customers would subscribe to the service. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f30b31",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Direct marketing generally refers to the relational marketing process involving getting information on individual consumers, getting feedback on their responses to various measures like sales campaigns, and influencing their behaviours (Bauer & Miglautsch, 1992). Many companies utilise direct marketing strategies to target individual groups of customers, reaching out specifically to groups of customers who will allow companies to meet their sales or business objectives (Moro et al., 2014), such as targeting advertising for a particular product to a specific group of customers who will be most likely to purchase that product. With the advent of rapidly advancing computer and database technologies, as well as the growing field of data science, companies and direct marketers now have unprecedented access to individual-level consumer information, which can be used to develop detailed customer profiles. These profiles are valuable to companies, providing them with great insight to guide the formulation of direct marketing campaigns, among other business strategies (Nowak & Phelps, 1995). As such, companies are keen to utilise technology to revolutionise marketing, using the information and metrics available to them to maximise the value they can get from each consumer over their lifetimes (Moro et al., 2014).\n",
    "\n",
    "Our project aims to predict whether individual customers will subscribe to a service provided by a company, based on demographic information collected about each customer. Should the model be good enough to predict whether customers are likely to subscribe to the service accurately, the company, a Portugese banking institution, would be able to target ads and marketing phone calls only at the new customers who are most likely to subscribe to this service, or similar services. This would result in huge savings in terms of company resources, freeing up campaign funds and human resources, which might have otherwise been wasted on calling reluctant customers, to be redirected to other services which might benefit the company more. It might also reduce annoyance in customers, as, ideally customers will only receive calls if they are likely to be interested in a product, and would not have to entertain calls or ads about products which they do not care about. This presents a win-win situation for both consumers and the company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d7b7c",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "## Data\n",
    "\n",
    "In this project, a dataset about direct marketing campaigns of a Portugese banking institution, from Sérgio Moro, P. Rita, and P. Cortez was used (Moro, S., Rita, P., and Cortez, P. 2012). The data was downloaded from UC Irvine's Machine Learning Repository, and the link can be found here: https://archive.ics.uci.edu/dataset/222/bank+marketing. The dataset has 16 features and 45211 instances, with each row representing information about a single client of the Portugese bank. The aim of the authors in creating the data set was to predict whether the client will subscribe a term deposit, which is captured by the 'subscribed' column. We have also used this column as our target in our analysis.\n",
    "\n",
    "\n",
    "## Analysis\n",
    "As our project is interested answering a classification problem, we decided to test different classification models to predict whether customers would subscribe to the term deposit. The models we chose to use are: the k-nearest neighbours (kNN), support vector machine (SVM), logistic regression, and random forest. We chose these models as they offer different benefits, and we were interested in finding out which model would work best for our data. We chose to include logistic regression as it offers both interpretability and potential to perform well in classification problems, while we chose the other models despite their lower interpretability as, in our case, it is not so critical that we understand why or how the model comes to its predictions as long as the model performs well. All variables from the original dataset except poutcome and contact were used to fit our models. 60% of the data was partitioned into the training set, and 40% of the data was partitioned into the test set, used for evaluating how well our best model would perform on unseen data. We used 5-fold cross-validation with the F-beta score (beta = 5) as the classification metric. Beta was chosen as 5 for the F-beta score as we would like to focus on making accurate predictions for the customers who might be interested in subscribing to the term deposit, corresponding to a higher recall. This is as because we would rather have false positives and annoy some customers who might not be interested in subscribing to our service, than miss out on customers who might want to subscribe to the service (false negatives), which would cause the bank to lose a potential opportunity. Furthermore, customers who fit this profile are more likely to subscribe to similar services, and if they are accurately identified, the bank will be able to target them more specifically in future campaigns. Numeric variables were standardised immediately before model testing and fitting, while categorical variables were encoded via one-hot encoding. The Python programming language (Van Rossum and Drake 2009) was used to perform the analysis, with the following Python packages being used as well: numpy(Harris et al. 2020), Pandas (McKinney 2010), altair (VanderPlas, 2018), scikit-learn (Pedregosa et al. 2011), matplotlib (Hunter, 2017).\n",
    "\n",
    "Note: Because Docker containers have resource limits for CPU, memory, and I/O. In order to speed up the running of complex models (such as SVM, Random Forest), we decided to reduce the proportion of the training set to 10%. This is acceptable because our dataset is large enough that a 10% split still has 2700+ entries. Ideally, the code should execute within five minutes, depending on your computer configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d8f37",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "We started our analysis by reading in the data from the repository. After doing exploratory data analysis of our data, we decided to drop the 'poutcome' and 'contact' features from our data, as there were many NaN values in the two feature columns for them, limiting the usefulness of these features in our model training and predictions. Plotting histograms of the features, coloured by class (whether the customer subscribed or not) revealed that the features were sufficiently differently distributed for us to be confident that we should include all other features in training our models. We also identified that there was great class imbalance in our target. As such, we decided not to use accuracy as the metric used to evaluate our model, as it would not give us a good idea of whether the model is performing well or not, preferring to use the F-beta score (beta = 5) instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a28eb-5154-4f11-ba9c-3214c962a686",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8721bb-a557-47d7-ad7b-6d493756dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "  \n",
    "# bank marketing data\n",
    "X = bank_marketing.data.features\n",
    "y = bank_marketing.data.targets\n",
    "\n",
    "# write raw data \"data/raw\" directory\n",
    "X.to_csv(\"data/raw/bank_marketing_train.csv\")\n",
    "y.to_csv(\"data/raw/bank_marketing_test.csv\")\n",
    "\n",
    "# concat features and targets\n",
    "bank_marketing_data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cdc26-a036-41d0-b193-363875f33535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename target 'y' as 'subscribed'\n",
    "bank_marketing_data.rename(columns={'y': 'subscribed'}, inplace=True)\n",
    "\n",
    "# create a preliminary split to explore data\n",
    "bank_marketing_train, bank_marketing_test = train_test_split(\n",
    "    bank_marketing_data, train_size=0.60, stratify=bank_marketing_data[\"subscribed\"]\n",
    ")\n",
    "\n",
    "bank_marketing_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397d70c-835f-493a-adb6-e4b3a7dc661d",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c4a9b-9933-48a3-bc2e-ba2970ff5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_summary = bank_marketing_train.describe(include = 'all')\n",
    "bank_marketing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316175d-dec4-417d-bbb3-9c7374fa2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NAs\n",
    "bank_marketing_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bank_marketing_train) # 60% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3d07b-ec43-464a-b98c-dc292135fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bank_marketing_data) # all the observations in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba5708-7538-4c89-88f5-4dff1c638c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of numerical columns\n",
    "numeric_cols = bank_marketing_train.select_dtypes(include=['number']).columns.to_list()\n",
    "for i in numeric_cols:\n",
    "    feature = i\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plot = bank_marketing_train.groupby(\"subscribed\")[feature].plot.hist(bins=20, alpha = 0.5, legend = True, density = True, title = \"Histogram of \" + feature)\n",
    "    plt.xlabel(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e54e8f-9cd0-48a1-8901-38fced96a8c0",
   "metadata": {},
   "source": [
    "Figure 1. Comparison of the empirical distributions of training data numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d677da-7ad9-420a-aa95-77df9e0537f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target class imbalance\n",
    "counts = bank_marketing_train[\"subscribed\"].value_counts()\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "counts.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Distribution of Target Values')\n",
    "ax.set_xlabel('Target')\n",
    "ax.set_ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee70f56-3f12-4056-85d9-5437312da75f",
   "metadata": {},
   "source": [
    "Figure 2. Comparison of the empirical distributions of target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8ad96-6adc-4437-a97b-1be13bceedfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values in categorical columns\n",
    "cat_cols = [\"job\", \"marital\", \"education\"]\n",
    "for column in cat_cols:\n",
    "    unique_values = list(bank_marketing_train[column].unique())\n",
    "    print(f\"{column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb5853-bf83-423d-aba8-af8fa6a9d9c9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e173bb-caf5-4cfa-a8a1-8ea5b9f4adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop poutcome, contact - too many na values\n",
    "bank_marketing_data = bank_marketing_data.drop([\"poutcome\", \"contact\"], axis = 1)\n",
    "bank_marketing_data = bank_marketing_data.dropna()\n",
    "bank_marketing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e240f-4dd8-41e4-b263-e9d0696aab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process data (e.g., scale and split into train & test)\n",
    "np.random.seed(522)\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# create the split\n",
    "# to speed up complex models, we reduce the proportion of the training set to 10%\n",
    "# the dataset is large enough that a 10% split still has 2700 entries\n",
    "bank_marketing_train, bank_marketing_test = train_test_split(\n",
    "    bank_marketing_data, train_size=0.10, stratify=bank_marketing_data[\"subscribed\"]\n",
    ")\n",
    "\n",
    "bank_marketing_train.to_csv(\"data/processed/bank_marketing_train.csv\")\n",
    "bank_marketing_test.to_csv(\"data/processed/bank_marketing_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558b3ef-9640-4efa-9b66-80781af0b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categorical_features = ['job', 'marital']\n",
    "ordinal_features = ['education']\n",
    "binary_features = ['default', 'housing', 'loan']\n",
    "drop_features = ['day_of_week', 'month']\n",
    "target = \"subscribed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43254b1e-6ed1-4c99-990c-ff81ace02e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bank_marketing_train.drop(columns=target)\n",
    "y_train = bank_marketing_train[target]\n",
    "X_test = bank_marketing_test.drop(columns=target)\n",
    "y_test = bank_marketing_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cde8a2-b6fe-4431-8fe6-ad1b8b41519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "education_order = ['primary', 'secondary', 'tertiary']\n",
    "ordinal_transformer = OrdinalEncoder(categories=[education_order], dtype=int)\n",
    "\n",
    "binary_transformer = OneHotEncoder(drop = 'if_binary', dtype=int, handle_unknown = \"ignore\", sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c9a84-cc83-4812-9d49-f37b4421f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),\n",
    "    (binary_transformer, binary_features),  \n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),  \n",
    ")\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "preprocessed_X_train = preprocessor.transform(X_train)\n",
    "preprocessed_X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# write raw data \"data/processed\" directory\n",
    "preprocessed_X_train.to_csv(\"data/processed/preprocessed_X_train.csv\")\n",
    "preprocessed_X_test.to_csv(\"data/processed/preprocessed_X_test.csv\")\n",
    "\n",
    "preprocessed_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0a74a-2579-4816-b9c7-47fbbb1ae883",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91a18cbd-36a5-4a49-8729-2c3c864d5577",
   "metadata": {},
   "source": [
    "We did hyperparameter optimisation for the following classification models: k-nearest neighbouts classifier, support vector machine, logistic regression, and random forest model. To find the best model, we performed 5-fold cross validation within GridSearch using F-beta score (beta = 5) as our metric of model prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6fc97-2add-40c3-b1d6-65c8e71f71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = { \"model_name\": [], \"mean_train_score\": [], \"mean_test_score\": [] }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b1f17",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3bd4e7-6c67-446c-983e-29571d2fc81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune model (here, find k for k-Nearest Neighbors classification using 5 fold cv)\n",
    "knn = KNNModel(np.arange(1, 10, 2))\n",
    "knn.set_preprocessor(preprocessor)\n",
    "knn.search_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97516789",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_scores_knn = knn.get_best_model_score()\n",
    "model_comparison[\"model_name\"].append(\"K-Nearest Neighbors\")\n",
    "model_comparison[\"mean_train_score\"].append(best_model_scores_knn[\"mean_train_score\"])\n",
    "model_comparison[\"mean_test_score\"].append(best_model_scores_knn[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60966c09-dc1f-4359-adb8-ac19e7cc7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_grid_knn = knn.get_accuracy_grid()\n",
    "accuracies_grid_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85938db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.draw_search_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275a554-c28a-444e-b501-0a32b1876920",
   "metadata": {},
   "source": [
    "Figure 3. Results from 5-fold cross validation of k-NN model to choose K. F-beta score (with beta = 5) was used as the classification metric as K was varied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2353d",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune model (here, find C for SVM model using 5 fold cv)\n",
    "svc = SVCModel(10.0 ** np.arange(-3, 3, 1))\n",
    "svc.set_preprocessor(preprocessor)\n",
    "svc.search_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_scores_svc = svc.get_best_model_score()\n",
    "model_comparison[\"model_name\"].append(\"SVC RBF\")\n",
    "model_comparison[\"mean_train_score\"].append(best_model_scores_svc[\"mean_train_score\"])\n",
    "model_comparison[\"mean_test_score\"].append(best_model_scores_svc[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_grid_svc = svc.get_accuracy_grid()\n",
    "accuracies_grid_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.draw_search_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbae135-57e7-41b0-82c0-e9b270e0706b",
   "metadata": {},
   "source": [
    "Figure 4. Results from 5-fold cross validation of SVM model to choose C. F-beta score (with beta = 5) was used as the classification metric as C was varied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbc720",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune model (here, find C for logistic regression using 5 fold cv)\n",
    "lr = LRModel(10.0 ** np.arange(-3, 5, 1))\n",
    "lr.set_preprocessor(preprocessor)\n",
    "lr.search_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ffac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_scores_lr = lr.get_best_model_score()\n",
    "model_comparison[\"model_name\"].append(\"Logistic Regression\")\n",
    "model_comparison[\"mean_train_score\"].append(best_model_scores_lr[\"mean_train_score\"])\n",
    "model_comparison[\"mean_test_score\"].append(best_model_scores_lr[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_grid_lr = lr.get_accuracy_grid()\n",
    "accuracies_grid_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.draw_search_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f842f3-0a29-4392-b989-6910d031d5fc",
   "metadata": {},
   "source": [
    "Figure 5. Results from 5-fold cross validation of logistic regression model to choose C. F-beta score (with beta = 5) was used as the classification metric as C was varied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7fcce",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune model (here, find n_estimator and max_depth for random forest classifier using 5 fold cv)\n",
    "rf = RFModel(n_estimators=[100, 200, 300, 400, 500], max_depth=[3, 5, 7, 15, None])\n",
    "rf.set_preprocessor(preprocessor)\n",
    "rf.search_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_scores_rf = rf.get_best_model_score()\n",
    "model_comparison[\"model_name\"].append(\"Random Forest\")\n",
    "model_comparison[\"mean_train_score\"].append(best_model_scores_rf[\"mean_train_score\"])\n",
    "model_comparison[\"mean_test_score\"].append(best_model_scores_rf[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_grid_rf = rf.get_accuracy_grid()\n",
    "accuracies_grid_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951ab2a-40ef-4ebb-a33c-47b21a6e065f",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc243ed-6821-4446-b24a-7eeb8ef04bba",
   "metadata": {},
   "source": [
    "Out of the above models, the random forest model performed the best, with its best, hyperparameter-optimised model having a mean test score of 0.833765, which was the highest mean test score for the optimised models. We thus decided to use the random forest model for our final predictions with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cefdb1-c6b9-4e88-8cb4-79c7041e26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a935f6b7-7ca3-4089-af91-6f0f951a8ef2",
   "metadata": {},
   "source": [
    "Table 1. Performance comparison across all models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5334bc7-4e1a-49ae-8ca8-36044c97957e",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236306c",
   "metadata": {},
   "source": [
    "The random forest model performed similarly on the test data when compared to the training data, having an F-beta score (beta = 5) of 0.817092 on the test data. This was only slightly lower than the mean test score of the best model after cross validation using the training data, which was 0.833765. This relatively high F-beta score and the small gap between the scores indicates that the model is quite good at predicting whether customers will subscribe to the term deposit, and is likely to generalise well to unseen data. It had quite a low accuracy, with 5492 false positives out of the 1807 actual positives. This is expected as we heavily favoured recall, and acceptable as the high number of false positives is not of large consequence to the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adabde36-4125-47e3-9285-aa2055e97d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy\n",
    "rf.fit(X_train, y_train)\n",
    "bank_marketing_fit = rf.model\n",
    "y_pred = bank_marketing_fit.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Compute F-beta score (beta = 5)\n",
    "bank_marketing_preds = X_test.assign(\n",
    "    predicted=bank_marketing_fit.predict(X_test)\n",
    ")\n",
    "f_beta_5_score = fbeta_score(\n",
    "    y_test,\n",
    "    bank_marketing_preds['predicted'],\n",
    "    beta=5,\n",
    "    pos_label='yes'\n",
    ")\n",
    "\n",
    "pd.DataFrame({'accuracy': [accuracy], 'F-beta score (beta = 5)': [f_beta_5_score]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056e759-f29e-4702-a81b-b4643c7f3b55",
   "metadata": {},
   "source": [
    "Table 2. Accuracy and F-beta score of model performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecf5b6-5f0c-472f-adc9-eb8e436ddd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    y_test,\n",
    "    bank_marketing_preds['predicted'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680746e5-88ae-44e2-b4c7-2e368772e39e",
   "metadata": {},
   "source": [
    "Table 3. Confusion matrix of model performance on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65771a97-188f-49ac-9af0-24450e1650df",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553f0d0",
   "metadata": {},
   "source": [
    "As the F-beta score (beta = 5) score of the model is quite high and the model does not seem to be overfit to the training data, it is probably safe to apply this model to new customers, and to predict whether they will be interested in subscribing to the term deposit. This means that the bank can target ads and direct marketing calls about this term deposit, and potentially, other related products, to this specific group of customers, and can expect that the success rate would be quite high compared to a random group of customers.\n",
    "\n",
    "While the high number of false positives is acceptable given the low-stakes nature of having false positives, it would still be beneficial to the bank to improve the performance of our model, and to reduce the number of false positives. In the future, the model may be refined by including more data points, which might help to train the model better. More relevant features may also be included to train the model better, and feature engineering may be carried out to further refine the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a75354",
   "metadata": {},
   "source": [
    "# References \n",
    "- Bauer, C. L., &amp; Miglautsch, J. (1992). A conceptual definition of direct marketing. Journal of Direct Marketing, 6(2), 7–17. https://doi.org/10.1002/dir.4000060204 \n",
    "- Harris, C.R. et al., 2020. Array programming with NumPy. Nature, 585, pp.357–362.\n",
    "- Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. Computing in Science &amp; Engineering, 9(3), 90–95.\n",
    "- McKinney, Wes. 2010. “Data Structures for Statistical Computing in Python.” In Proceedings of the 9th Python in Science Conference, edited by Stéfan van der Walt and Jarrod Millman, 51–56.\n",
    "- Moro, S., Cortez, P., &amp; Rita, P. (2014). A data-driven approach to predict the success of bank telemarketing. Decision Support Systems, 62, 22–31. https://doi.org/10.1016/j.dss.2014.03.001 \n",
    "- Moro,S., Rita,P., and Cortez,P.. (2012). Bank Marketing. UCI Machine Learning Repository. https://doi.org/10.24432/C5K306. \n",
    "- Nowak, G. J., &amp; Phelps, J. (1995). Direct marketing and the use of individual-level consumer information: Determining how and when “privacy” matters. Journal of Direct Marketing, 9(3), 46–60. https://doi.org/10.1002/dir.4000090307\n",
    "- Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "- VanderPlas, J. et al., 2018. Altair: Interactive statistical visualizations for python. Journal of open source software, 3(32), p.1057.\n",
    "- Van Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference Manual. Scotts Valley, CA: CreateSpace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
