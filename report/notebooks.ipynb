{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics for Direct Marketing Campaign: A Banking Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Gretel Tan, Yan Zeng, Charles Xu & Riya E. Shaju 2023/11/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams, cycler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from myst_nb import glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "0.638"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "accuracy"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "0.816"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "F-beta score (beta = 5)"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n</style>\n<table id=\"T_449b3\">\n  <thead>\n    <tr>\n      <th id=\"T_449b3_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n      <th id=\"T_449b3_level0_col1\" class=\"col_heading level0 col1\" >F-beta score (beta = 5)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_449b3_row0_col0\" class=\"data row0 col0\" >0.638000</td>\n      <td id=\"T_449b3_row0_col1\" class=\"data row0 col1\" >0.816000</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x1405de0e0>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "test_scores_df"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_scores_df = pd.read_csv(\"../results/tables/best_model_score.csv\").round(3)\n",
    "glue(\"accuracy\", test_scores_df['accuracy'].values[0], display=False)\n",
    "glue(\"F-beta score (beta = 5)\", test_scores_df['F-beta score (beta = 5)'].values[0], display=False)\n",
    "test_scores_df = test_scores_df.iloc[:, 1:3].style.format().hide()\n",
    "glue(\"test_scores_df\", test_scores_df, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "0.828"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "rf_mean_test_score"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n</style>\n<table id=\"T_11829\">\n  <thead>\n    <tr>\n      <th id=\"T_11829_level0_col0\" class=\"col_heading level0 col0\" >model_name</th>\n      <th id=\"T_11829_level0_col1\" class=\"col_heading level0 col1\" >mean_train_score</th>\n      <th id=\"T_11829_level0_col2\" class=\"col_heading level0 col2\" >mean_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_11829_row0_col0\" class=\"data row0 col0\" >K-Nearest Neighbors</td>\n      <td id=\"T_11829_row0_col1\" class=\"data row0 col1\" >0.475000</td>\n      <td id=\"T_11829_row0_col2\" class=\"data row0 col2\" >0.243000</td>\n    </tr>\n    <tr>\n      <td id=\"T_11829_row1_col0\" class=\"data row1 col0\" >SVC RBF</td>\n      <td id=\"T_11829_row1_col1\" class=\"data row1 col1\" >0.826000</td>\n      <td id=\"T_11829_row1_col2\" class=\"data row1 col2\" >0.779000</td>\n    </tr>\n    <tr>\n      <td id=\"T_11829_row2_col0\" class=\"data row2 col0\" >Logistic Regression</td>\n      <td id=\"T_11829_row2_col1\" class=\"data row2 col1\" >0.781000</td>\n      <td id=\"T_11829_row2_col2\" class=\"data row2 col2\" >0.774000</td>\n    </tr>\n    <tr>\n      <td id=\"T_11829_row3_col0\" class=\"data row3 col0\" >Random Forest</td>\n      <td id=\"T_11829_row3_col1\" class=\"data row3 col1\" >0.839000</td>\n      <td id=\"T_11829_row3_col2\" class=\"data row3 col2\" >0.828000</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x106eac4f0>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "model_comparison_df"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_comparison_df = pd.read_csv(\"../results/tables/model_comparison.csv\").round(3)\n",
    "glue(\"rf_mean_test_score\", model_comparison_df['mean_test_score'].values[3], display=False)\n",
    "model_comparison_df = model_comparison_df.iloc[:, 1:4].style.format().hide()\n",
    "glue(\"model_comparison_df\", model_comparison_df, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "38874"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "total"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "24786"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "pred_correct"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "415"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "false_neg"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted: no</th>\n      <th>yes</th>\n    </tr>\n    <tr>\n      <th>Actual label:</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>no</th>\n      <td>20682</td>\n      <td>13673</td>\n    </tr>\n    <tr>\n      <th>yes</th>\n      <td>415</td>\n      <td>4104</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "application/papermill.record/text/plain": "               Predicted: no    yes\nActual label:                      \nno                     20682  13673\nyes                      415   4104"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "confusion_df"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_df=pd.read_csv(\"../results/tables/best_model_confusion_matrix.csv\", index_col='subscribed')\n",
    "confusion_df.rename(columns={'no':'Predicted: no'}, inplace=True)\n",
    "confusion_df.index.names = ['Actual label:']\n",
    "glue(\"total\", confusion_df.sum(axis=1).sum(), display=False)\n",
    "glue(\"pred_correct\", confusion_df['Predicted: no'].values[0] + confusion_df['yes'].values[1], display=False)\n",
    "glue(\"false_positives\", confusion_df['yes'].values[0], display=False)\n",
    "glue(\"actual_positives\", confusion_df['yes'].values[1], display=False)\n",
    "glue(\"confusion_df\", confusion_df, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this project, we aimed to use customer information from a phone-call based direct marketing campaign of a Portugese banking institution to predict whether customers would subscribe to the product offered, a term deposit. We applied several classification based models (k-NN, SVM, logistic regression and random forest) to our dataset to find the model which best fit our data, eventually settling on the random forest model, which performed the best among all the models tested, with an F-beta score with beta = 5 of {glue:text}`F-beta score (beta = 5)`, and an accuracy of {glue:text}`accuracy` on the test data.\n",
    "\n",
    "While this was the best performing model out of the models tested, its accuracy still left much to be desired. This indicates that perhaps more data is needed to accurately predict whether customers would subscribe to the term deposit. Future studies may also consider using more features, a different set of features which might be more relevant to whether customers will subscribe, or utilising feature engineering to obtain features which might be more useful in helping to predict whether customers would subscribe to the service. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Direct marketing generally refers to the relational marketing process involving getting information on individual consumers, getting feedback on their responses to various measures like sales campaigns, and influencing their behaviours {cite}`Bauer1992`. Many companies utilise direct marketing strategies to target individual groups of customers, reaching out specifically to groups of customers who will allow companies to meet their sales or business objectives {cite}`Moro2012`, such as targeting advertising for a particular product to a specific group of customers who will be most likely to purchase that product. With the advent of rapidly advancing computer and database technologies, as well as the growing field of data science, companies and direct marketers now have unprecedented access to individual-level consumer information, which can be used to develop detailed customer profiles. These profiles are valuable to companies, providing them with great insight to guide the formulation of direct marketing campaigns, among other business strategies {cite}`Nowak1995`. As such, companies are keen to utilise technology to revolutionise marketing, using the information and metrics available to them to maximise the value they can get from each consumer over their lifetimes {cite}`Moro2012`.\n",
    "\n",
    "Our project aims to predict whether individual customers will subscribe to a service provided by a company, based on demographic information collected about each customer. Should the model be good enough to predict whether customers are likely to subscribe to the service accurately, the company, a Portugese banking institution, would be able to target ads and marketing phone calls only at the new customers who are most likely to subscribe to this service, or similar services. This would result in huge savings in terms of company resources, freeing up campaign funds and human resources, which might have otherwise been wasted on calling reluctant customers, to be redirected to other services which might benefit the company more. It might also reduce annoyance in customers, as, ideally customers will only receive calls if they are likely to be interested in a product, and would not have to entertain calls or ads about products which they do not care about. This presents a win-win situation for both consumers and the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "## Data\n",
    "\n",
    "In this project, a dataset about direct marketing campaigns of a Portugese banking institution, from SÃ©rgio Moro, P. Rita, and P. Cortez was used {cite}`Moro2012`. The data was downloaded from UC Irvine's Machine Learning Repository, and the link can be found [here](https://archive.ics.uci.edu/dataset/222/bank+marketing). The dataset has 16 features and 45211 instances, with each row representing information about a single client of the Portugese bank. The aim of the authors in creating the data set was to predict whether the client will subscribe a term deposit, which is captured by the 'subscribed' column. We have also used this column as our target in our analysis.\n",
    "\n",
    "\n",
    "## Analysis\n",
    "As our project is interested answering a classification problem, we decided to test different classification models to predict whether customers would subscribe to the term deposit. The models we chose to use are: the k-nearest neighbours (kNN), support vector machine (SVM), logistic regression, and random forest. We chose these models as they offer different benefits, and we were interested in finding out which model would work best for our data. We chose to include logistic regression as it offers both interpretability and potential to perform well in classification problems, while we chose the other models despite their lower interpretability as, in our case, it is not so critical that we understand why or how the model comes to its predictions as long as the model performs well. All variables from the original dataset except poutcome and contact were used to fit our models. 10% of the data was partitioned into the training set, and 90% of the data was partitioned into the test set, used for evaluating how well our best model would perform on unseen data. We used 5-fold cross-validation with the F-beta score (beta = 5) as the classification metric. Beta was chosen as 5 for the F-beta score as we would like to focus on making accurate predictions for the customers who might be interested in subscribing to the term deposit, corresponding to a higher recall. This is as because we would rather have false positives and annoy some customers who might not be interested in subscribing to our service, than miss out on customers who might want to subscribe to the service (false negatives), which would cause the bank to lose a potential opportunity. Furthermore, customers who fit this profile are more likely to subscribe to similar services, and if they are accurately identified, the bank will be able to target them more specifically in future campaigns. Numeric variables were standardised immediately before model testing and fitting, while categorical variables were encoded via one-hot encoding. The Python programming language {cite}`Python` was used to perform the analysis, with the following Python packages being used as well: {cite}`numpy`, {cite}`mckinney-proc-scipy-2010`, {cite}`altair`, {cite}`scikit-learn`, {cite}`Hunter2007`. The code used to perform the analysis and create this report can be found here: https://github.com/UBC-MDS/Group_7_Project.\n",
    "\n",
    "Note: Because Docker containers have resource limits for CPU, memory, and I/O. In order to speed up the running of complex models (such as SVM, Random Forest), we decided to reduce the proportion of the training set to 10%. This is acceptable because our dataset is large enough that a 10% split still has 4500+ entries. Ideally, the code should execute within five minutes, depending on your computer configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results & Discussion\n",
    "\n",
    "We started our analysis by reading in the data from the repository. After doing exploratory data analysis of our data, we decided to drop the 'poutcome' and 'contact' features from our data, as there were many NaN values in the two feature columns for them, limiting the usefulness of these features in our model training and predictions. Plotting histograms of the features, coloured by class (whether the customer subscribed or not) revealed that the features were sufficiently differently distributed for us to be confident that we should include all other features in training our models. We also identified that there was great class imbalance in our target. As such, we decided not to use accuracy as the metric used to evaluate our model, as it would not give us a good idea of whether the model is performing well or not, preferring to use the F-beta score (beta = 5) instead. \n",
    "\n",
    "TODO\n",
    "\n",
    "We did hyperparameter optimisation for the following classification models: k-nearest neighbouts classifier ({numref}`Figure {number} <knn>`), support vector machine ({numref}`Figure {number} <svc>`), logistic regression ({numref}`Figure {number} <lr>`), and random forest model ({numref}`Figure {number} <rf>`). To find the best model, we performed 5-fold cross validation within GridSearch using F-beta score (beta = 5) as our metric of model prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/plots/knn.png\n",
    "---\n",
    "width: 600px\n",
    "name: knn\n",
    "---\n",
    "Results from 5-fold cross validation of k-NN model to choose K. F-beta score (with beta = 5) was used as the classification metric as K was varied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/plots/svc.png\n",
    "---\n",
    "width: 600px\n",
    "name: svc\n",
    "---\n",
    "Results from 5-fold cross validation of SVM model to choose C. F-beta score (with beta = 5) was used as the classification metric as C was varied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/plots/lr.png\n",
    "---\n",
    "width: 600px\n",
    "name: lr\n",
    "---\n",
    "Results from 5-fold cross validation of logistic regression model to choose C. F-beta score (with beta = 5) was used as the classification metric as C was varied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/plots/rf.png\n",
    "---\n",
    "width: 600px\n",
    "name: rf\n",
    "---\n",
    "Results from 5-fold cross validation of random forest model to choose max_features and max_depth. F-beta score (with beta = 5) was used as the classification metric as max_features and max_depth were varied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the above models, the random forest model performed the best, with its best, hyperparameter-optimised model having a mean test score of {glue:text}`rf_mean_test_score`, which was the highest mean test score for the optimised models. We thus decided to use the random forest model for our final predictions with the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} model_comparison_df\n",
    "---\n",
    "width: 400px\n",
    "name: \"model_comparison_df\"\n",
    "---\n",
    "Performance comparison across all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performed similarly on the test data when compared to the training data, having an F-beta score (beta = 5) of {glue:text}`F-beta score (beta = 5)` on the test data. This was only slightly lower than the mean test score of the best model after cross validation using the training data, which was {glue:text}`rf_mean_test_score`. This relatively high F-beta score and the small gap between the scores indicates that the model is quite good at predicting whether customers will subscribe to the term deposit, and is likely to generalise well to unseen data. It had quite a low accuracy, with {glue:text}`false_positives` false positives and {glue:text}`actual_positives` actual positives. This is expected as we heavily favoured recall, and acceptable as the high number of false positives is not of large consequence to the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} test_scores_df\n",
    "---\n",
    "width: 400px\n",
    "name: \"test_scores_df\"\n",
    "---\n",
    "Accuracy and F-beta score of model performance on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} confusion_df\n",
    "---\n",
    "width: 650px\n",
    "name: \"confusion_df\"\n",
    "---\n",
    "Confusion matrix of model performance on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the F-beta score (beta = 5) score of the model is quite high and the model does not seem to be overfit to the training data, it is probably safe to apply this model to new customers, and to predict whether they will be interested in subscribing to the term deposit. This means that the bank can target ads and direct marketing calls about this term deposit, and potentially, other related products, to this specific group of customers, and can expect that the success rate would be quite high compared to a random group of customers.\n",
    "\n",
    "While the high number of false positives is acceptable given the low-stakes nature of having false positives, it would still be beneficial to the bank to improve the performance of our model, and to reduce the number of false positives. In the future, the model may be refined by including more data points, which might help to train the model better. More relevant features may also be included to train the model better, and feature engineering may be carried out to further refine the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography\n",
    "filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
